{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aaa02648-9eae-45ba-893f-88440e8e4235",
   "metadata": {},
   "source": [
    "![clothing_classification](clothing_classification.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5a988c-1095-485a-a88c-002400a872be",
   "metadata": {},
   "source": [
    "Fashion Forward is a new AI-based e-commerce clothing retailer.\n",
    "They want to use image classification to automatically categorize new product listings, making it easier for customers to find what they're looking for. It will also assist in inventory management by quickly sorting items.\n",
    "\n",
    "As a data scientist tasked with implementing a garment classifier, your primary objective is to develop a machine learning model capable of accurately categorizing images of clothing items into distinct garment types such as shirts, trousers, shoes, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa73ab28",
   "metadata": {},
   "source": [
    "Automate product tagging for the e-commerce store using CNNs.\n",
    "\n",
    "Once trained (keeping the epochs to 1 or 2 to keep the run time down), store your predictions on the test set in a list named predictions.\n",
    "\n",
    "Calculate the accuracy, and per-class precision and recall for your classifier based on the predictions obtained. Store your metrics in variables named accuracy, precision, and recall. Use lists of the appropriate length for the precision and recall."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4a1ab317-f3e4-4e5f-93a7-9c27677c5ffb",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 49,
    "lastExecutedAt": 1757596744908,
    "lastExecutedByKernel": "950a0561-c6a7-48cb-91f9-643b5f69a042",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Run the cells below first"
   },
   "outputs": [],
   "source": [
    "# Run the cells below first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea8065b7-84fc-4376-afef-6db731dec4b3",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 48,
    "lastExecutedAt": 1757596744956,
    "lastExecutedByKernel": "950a0561-c6a7-48cb-91f9-643b5f69a042",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "import numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchmetrics import Accuracy, Precision, Recall"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy, Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "662e1bf1-943f-4243-9fd4-02ce11609e8d",
   "metadata": {
    "collapsed": true,
    "executionCancelledAt": null,
    "executionTime": 134,
    "jupyter": {
     "outputs_hidden": true,
     "source_hidden": false
    },
    "lastExecutedAt": 1757596745091,
    "lastExecutedByKernel": "950a0561-c6a7-48cb-91f9-643b5f69a042",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Load datasets\nfrom torchvision import datasets\nimport torchvision.transforms as transforms\n\ntrain_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\ntest_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())",
    "outputsMetadata": {
     "0": {
      "height": 80,
      "type": "stream"
     },
     "1": {
      "height": 38,
      "type": "stream"
     },
     "2": {
      "height": 122,
      "type": "stream"
     },
     "3": {
      "height": 38,
      "type": "stream"
     },
     "4": {
      "height": 122,
      "type": "stream"
     },
     "5": {
      "height": 38,
      "type": "stream"
     },
     "6": {
      "height": 122,
      "type": "stream"
     },
     "7": {
      "height": 38,
      "type": "stream"
     },
     "8": {
      "height": 59,
      "type": "stream"
     }
    }
   },
   "outputs": [],
   "source": [
    "# Load datasets\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_data = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\n",
    "test_data = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "53c0a71d-d7d9-4a11-8a9b-55867ea7e0b5",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 52,
    "lastExecutedAt": 1757596745144,
    "lastExecutedByKernel": "950a0561-c6a7-48cb-91f9-643b5f69a042",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Start coding here\n# Use as many cells as you need"
   },
   "outputs": [],
   "source": [
    "# Start coding here\n",
    "# Use as many cells as you need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "95eef8e2-1734-4cfa-a4e0-0172e3a5ef0b",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 47,
    "lastExecutedAt": 1757596745192,
    "lastExecutedByKernel": "950a0561-c6a7-48cb-91f9-643b5f69a042",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# Get the number of classes\nclasses = train_data.classes\nnum_classes = len(train_data.classes)\n\n# Define some relevant variables\nnum_input_channels = 1\nnum_output_channels = 16\nimage_size = train_data[0][0].shape[1]"
   },
   "outputs": [],
   "source": [
    "# Get the number of classes\n",
    "classes = train_data.classes\n",
    "num_classes = len(train_data.classes)\n",
    "\n",
    "# Define some relevant variables\n",
    "num_input_channels = 1\n",
    "num_output_channels = 16\n",
    "image_size = train_data[0][0].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "91bd26b5-4681-4d12-89a3-420f8345f931",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 51,
    "lastExecutedAt": 1757596745244,
    "lastExecutedByKernel": "950a0561-c6a7-48cb-91f9-643b5f69a042",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# 1. Defining the CNN (Convolutional Neural Network)\n# Define CNN\nclass MultiClassImageClassifier(nn.Module): # Creating a class to contain the layers of a CNN\n    def __init__(self):\n        super(MultiClassImageClassifier, self).__init__()\n        self.conv = nn.Conv2d(in_channels = num_input_channels, out_channels = num_output_channels, kernel_size=3, stride=1, padding=1) # Adding a convolutional layer\n        self.relu = nn.ReLU() # Adding a Rectilinear Unit\n        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2) # Adding a pooling layer\n        self.flatten = nn.Flatten()  # flatten the input\n\n        # Create a fully connected layer\n        self.fc = nn.Linear(num_output_channels * (image_size//2)**2, num_classes) # Adding a fully connected layer\n\n    def forward(self, x): # Defining a .forward() method\n        # Pass inputs through each layer\n        x = self.conv(x)\n        x = self.relu(x)\n        x = self.maxpool(x)\n        x = self.flatten(x)\n        x = self.fc(x)\n        return x\n"
   },
   "outputs": [],
   "source": [
    "# 1. Defining the CNN (Convolutional Neural Network)\n",
    "# Define CNN\n",
    "class MultiClassImageClassifier(nn.Module): # Creating a class to contain the layers of a CNN\n",
    "    def __init__(self):\n",
    "        super(MultiClassImageClassifier, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels = num_input_channels, out_channels = num_output_channels, kernel_size=3, stride=1, padding=1) # Adding a convolutional layer\n",
    "        self.relu = nn.ReLU() # Adding a Rectilinear Unit\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2) # Adding a pooling layer\n",
    "        self.flatten = nn.Flatten()  # flatten the input\n",
    "\n",
    "        # Create a fully connected layer\n",
    "        self.fc = nn.Linear(num_output_channels * (image_size//2)**2, num_classes) # Adding a fully connected layer\n",
    "\n",
    "    def forward(self, x): # Defining a .forward() method\n",
    "        # Pass inputs through each layer\n",
    "        x = self.conv(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "67205471-1356-4220-8ec8-a0bcb35cd283",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 70275,
    "lastExecutedAt": 1757596815520,
    "lastExecutedByKernel": "950a0561-c6a7-48cb-91f9-643b5f69a042",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# 2. Training the CNN\n\n# Define the training set DataLoader\ndataloader_train = DataLoader(\n    train_data,\n    batch_size=10,\n    shuffle=True,\n)\n\n# Define training function\ndef train_model(optimizer, net, num_epochs):\n    num_processed = 0\n    criterion = nn.CrossEntropyLoss()\n    for epoch in range(num_epochs):\n        running_loss = 0\n        num_processed = 0\n        for features, labels in dataloader_train:\n            optimizer.zero_grad()\n            outputs = net(features)\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n            num_processed += len(labels)\n        print(f'epoch {epoch}, loss: {running_loss / num_processed}')\n        \n    train_loss = running_loss / len(dataloader_train)\n\n# Train for 1 epoch\nnet = MultiClassImageClassifier()  # <-- FIXED: removed num_classes argument\noptimizer = optim.Adam(net.parameters(), lr=0.001)\n\ntrain_model(\n    optimizer=optimizer,\n    net=net,\n    num_epochs=1,\n)",
    "outputsMetadata": {
     "0": {
      "height": 38,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0, loss: 0.03969368415138645\n"
     ]
    }
   ],
   "source": [
    "# 2. Training the CNN\n",
    "\n",
    "# Define the training set DataLoader\n",
    "dataloader_train = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Define training function\n",
    "def train_model(optimizer, net, num_epochs):\n",
    "    num_processed = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        num_processed = 0\n",
    "        for features, labels in dataloader_train:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            num_processed += len(labels)\n",
    "        print(f'epoch {epoch}, loss: {running_loss / num_processed}')\n",
    "        \n",
    "    train_loss = running_loss / len(dataloader_train)\n",
    "\n",
    "# Train for 1 epoch\n",
    "net = MultiClassImageClassifier()  # <-- FIXED: removed num_classes argument\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train_model(\n",
    "    optimizer=optimizer,\n",
    "    net=net,\n",
    "    num_epochs=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "da6ab1ed-d93f-4c07-aeba-c1e3c7921f53",
   "metadata": {
    "executionCancelledAt": null,
    "executionTime": 11455,
    "lastExecutedAt": 1757596826975,
    "lastExecutedByKernel": "950a0561-c6a7-48cb-91f9-643b5f69a042",
    "lastScheduledRunId": null,
    "lastSuccessfullyExecutedCode": "# 3. Testing the CNN\n\n\n# Test the model on the test set\n              \n# Define the test set DataLoader\ndataloader_test = DataLoader(\n    test_data,\n    batch_size=10,\n    shuffle=False,\n)\n# Define the metrics\naccuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\nprecision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\nrecall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)\n\n# Run model on test set\nnet.eval()\npredictions = []\nfor i, (features, labels) in enumerate(dataloader_test):\n    output = net.forward(features.reshape(-1, 1, image_size, image_size))\n    cat = torch.argmax(output, dim=-1)\n    predictions.extend(cat.tolist())\n    accuracy_metric(cat, labels)\n    precision_metric(cat, labels)\n    recall_metric(cat, labels)\n\n# Compute the metrics\naccuracy = accuracy_metric.compute().item()\nprecision = precision_metric.compute().tolist()\nrecall = recall_metric.compute().tolist()\nprint('Accuracy:', accuracy)\nprint('Precision (per class):', precision)\nprint('Recall (per class):', recall)",
    "outputsMetadata": {
     "0": {
      "height": 122,
      "type": "stream"
     }
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8779000043869019\n",
      "Precision (per class): [0.8836363554000854, 0.9978991746902466, 0.818092405796051, 0.7851170301437378, 0.8211716413497925, 0.9632571935653687, 0.6676245331764221, 0.9438315033912659, 0.9756592512130737, 0.9571285843849182]\n",
      "Recall (per class): [0.7289999723434448, 0.949999988079071, 0.8320000171661377, 0.9390000104904175, 0.7990000247955322, 0.9700000286102295, 0.6970000267028809, 0.9409999847412109, 0.9620000123977661, 0.9599999785423279]\n"
     ]
    }
   ],
   "source": [
    "# 3. Testing the CNN\n",
    "\n",
    "\n",
    "# Test the model on the test set\n",
    "              \n",
    "# Define the test set DataLoader\n",
    "dataloader_test = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    ")\n",
    "# Define the metrics\n",
    "accuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "precision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\n",
    "recall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)\n",
    "\n",
    "# Run model on test set\n",
    "net.eval()\n",
    "predictions = []\n",
    "for i, (features, labels) in enumerate(dataloader_test):\n",
    "    output = net.forward(features.reshape(-1, 1, image_size, image_size))\n",
    "    cat = torch.argmax(output, dim=-1)\n",
    "    predictions.extend(cat.tolist())\n",
    "    accuracy_metric(cat, labels)\n",
    "    precision_metric(cat, labels)\n",
    "    recall_metric(cat, labels)\n",
    "\n",
    "# Compute the metrics\n",
    "accuracy = accuracy_metric.compute().item()\n",
    "precision = precision_metric.compute().tolist()\n",
    "recall = recall_metric.compute().tolist()\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision (per class):', precision)\n",
    "print('Recall (per class):', recall)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2027f4dc",
   "metadata": {},
   "source": [
    "Guid\n",
    "\n",
    "How to approach the project\n",
    "1. Defining the CNN (Convolutional Neural Network)\n",
    "\n",
    "2. Training the CNN\n",
    "\n",
    "3. Testing the CNN\n",
    "\n",
    "Steps to complete\n",
    "\n",
    "1\n",
    "Defining the CNN (Convolutional Neural Network)\n",
    "Define a class containing all the appropriate layers, and a method to perform the forward pass of a batch of images.\n",
    "\n",
    "\n",
    "Creating a class to contain the layers of a CNN\n",
    "You could define a class that inherits from PyTorch's nn.module class.\n",
    "\n",
    "\n",
    "\n",
    "Adding a convolutional layer\n",
    "You could use PyTorch's nn.Conv2D() class to define the convolutional layer.\n",
    "Create an instance of it in your CNN class's constructor and assign it to an instance variable such as self.conv.\n",
    "\n",
    "\n",
    "\n",
    "Adding a Rectilinear Unit\n",
    "You could use PyTorch's nn.ReLU() class.\n",
    "Create an instance of it in your CNN class's constructor and assign it to an instance variable such as self.relu.\n",
    "\n",
    "\n",
    "\n",
    "Adding a pooling layer\n",
    "You could use PyTorch's nn.MaxPool2D() class.\n",
    "Create an instance of it in your CNN class's constructor and assign it to an instance variable such as self.maxpool.\n",
    "\n",
    "\n",
    "\n",
    "Adding a fully connected layer\n",
    "You could use PyTorch's nn.Linear() class.\n",
    "Create an instance of it in your CNN class's constructor and assign it to an instance variable such as self.fc.\n",
    "You will also need to flatten the input first, which could be done with an instance of nn.Flatten\n",
    "\n",
    "\n",
    "\n",
    "Defining a .forward() method\n",
    "Finally, you'll need to define a .forward() method that passes the input through each layer and returns the output.\n",
    "\n",
    "\n",
    "\n",
    "2\n",
    "Training the CNN\n",
    "Define a training loop that loops over the dataset, calculating the loss and propagating it backwards through the network.\n",
    "\n",
    "\n",
    "Define a suitable loss criterion\n",
    "PyTorch's nn.CrossEntropyLoss() could be used here, since this is a multi-class classification problem.\n",
    "\n",
    "\n",
    "\n",
    "Define an optimizer\n",
    "You could use PyTorch's optim.Adam() optimizer here.\n",
    "\n",
    "\n",
    "\n",
    "3\n",
    "Testing the CNN\n",
    "Use your trained model to classify the images in the test set, and calculate the appropriate metrics.\n",
    "\n",
    "\n",
    "Predict the category of each image in the test data.\n",
    "You'll need to use the .forward() method on your CNN class to pass the test images through the network.\n",
    "You could use torch.argmax() to find the category with the highest predicted probability.\n",
    "\n",
    "\n",
    "\n",
    "Calculate the performance metrics\n",
    "You could use Accuracy(), Precision(), and Recall() from torchmetrics to calculate the"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4669bb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Solution ####\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchmetrics import Accuracy, Precision, Recall\n",
    "\n",
    "# Dataset loading not copied here, please refer to the notebook for this\n",
    "\n",
    "# Get the number of classes\n",
    "classes = train_data.classes\n",
    "num_classes = len(train_data.classes)\n",
    "\n",
    "# Define some relevant variables\n",
    "num_input_channels = 1\n",
    "num_output_channels = 16\n",
    "image_size = train_data[0][0].shape[1]\n",
    "\n",
    "# Define CNN\n",
    "class MultiClassImageClassifier(nn.Module):\n",
    "  \n",
    "    # Define the init method\n",
    "    def __init__(self, num_classes):\n",
    "        super(MultiClassImageClassifier, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(num_input_channels, num_output_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Create a fully connected layer\n",
    "        self.fc = nn.Linear(num_output_channels * (image_size//2)**2, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Pass inputs through each layer\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x)\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "      \n",
    "# Define the training set DataLoader\n",
    "dataloader_train = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=10,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "# Define training function\n",
    "def train_model(optimizer, net, num_epochs):\n",
    "    num_processed = 0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0\n",
    "        num_processed = 0\n",
    "        for features, labels in dataloader_train:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = net(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "            num_processed += len(labels)\n",
    "        print(f'epoch {epoch}, loss: {running_loss / num_processed}')\n",
    "        \n",
    "    train_loss = running_loss / len(dataloader_train)\n",
    "\n",
    "\n",
    "# Train for 1 epoch\n",
    "net = MultiClassImageClassifier(num_classes)\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)\n",
    "\n",
    "train_model(\n",
    "    optimizer=optimizer,\n",
    "    net=net,\n",
    "    num_epochs=1,\n",
    ")\n",
    "\n",
    "# Test the model on the test set\n",
    "              \n",
    "# Define the test set DataLoader\n",
    "dataloader_test = DataLoader(\n",
    "    test_data,\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    ")\n",
    "# Define the metrics\n",
    "accuracy_metric = Accuracy(task='multiclass', num_classes=num_classes)\n",
    "precision_metric = Precision(task='multiclass', num_classes=num_classes, average=None)\n",
    "recall_metric = Recall(task='multiclass', num_classes=num_classes, average=None)\n",
    "\n",
    "# Run model on test set\n",
    "net.eval()\n",
    "predictions = []\n",
    "for i, (features, labels) in enumerate(dataloader_test):\n",
    "    output = net.forward(features.reshape(-1, 1, image_size, image_size))\n",
    "    cat = torch.argmax(output, dim=-1)\n",
    "    predictions.extend(cat.tolist())\n",
    "    accuracy_metric(cat, labels)\n",
    "    precision_metric(cat, labels)\n",
    "    recall_metric(cat, labels)\n",
    "\n",
    "# Compute the metrics\n",
    "accuracy = accuracy_metric.compute().item()\n",
    "precision = precision_metric.compute().tolist()\n",
    "recall = recall_metric.compute().tolist()\n",
    "print('Accuracy:', accuracy)\n",
    "print('Precision (per class):', precision)\n",
    "print('Recall (per class):', recall)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "Welcome to DataCamp Workspaces.ipynb",
   "provenance": []
  },
  "editor": "DataLab",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
